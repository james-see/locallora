<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LocalLoRA - Fine-tune LLMs on Apple Silicon</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=Space+Grotesk:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-primary: #0a0a0f;
            --bg-secondary: #12121a;
            --bg-card: #1a1a24;
            --text-primary: #e4e4e7;
            --text-secondary: #a1a1aa;
            --accent: #22d3ee;
            --accent-dim: #0891b2;
            --border: #27272a;
            --code-bg: #18181b;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Space Grotesk', sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.7;
            min-height: 100vh;
        }

        .grain {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            opacity: 0.03;
            background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noise'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noise)'/%3E%3C/svg%3E");
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }

        header {
            text-align: center;
            padding: 4rem 0 3rem;
            border-bottom: 1px solid var(--border);
            margin-bottom: 3rem;
        }

        .logo {
            font-size: 3.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, var(--accent) 0%, #a78bfa 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 1rem;
            letter-spacing: -0.02em;
        }

        .tagline {
            color: var(--text-secondary);
            font-size: 1.2rem;
            margin-bottom: 2rem;
        }

        .badges {
            display: flex;
            gap: 0.75rem;
            justify-content: center;
            flex-wrap: wrap;
        }

        .badge {
            background: var(--bg-card);
            border: 1px solid var(--border);
            padding: 0.4rem 0.9rem;
            border-radius: 20px;
            font-size: 0.85rem;
            color: var(--text-secondary);
        }

        .badge.accent {
            border-color: var(--accent-dim);
            color: var(--accent);
        }

        h2 {
            font-size: 1.75rem;
            margin: 3rem 0 1.5rem;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        h2::before {
            content: '';
            display: block;
            width: 4px;
            height: 1.5rem;
            background: var(--accent);
            border-radius: 2px;
        }

        .faq-item {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            margin-bottom: 1rem;
            overflow: hidden;
        }

        .faq-question {
            padding: 1.25rem 1.5rem;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-weight: 600;
            transition: background 0.2s;
        }

        .faq-question:hover {
            background: var(--bg-secondary);
        }

        .faq-question::after {
            content: '+';
            font-size: 1.5rem;
            color: var(--accent);
            transition: transform 0.3s;
        }

        .faq-item.open .faq-question::after {
            transform: rotate(45deg);
        }

        .faq-answer {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }

        .faq-item.open .faq-answer {
            max-height: 1000px;
        }

        .faq-content {
            padding: 0 1.5rem 1.5rem;
            color: var(--text-secondary);
        }

        pre {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1rem;
            overflow-x: auto;
            margin: 1rem 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85rem;
            line-height: 1.6;
        }

        code {
            font-family: 'JetBrains Mono', monospace;
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-size: 0.9em;
        }

        pre code {
            background: none;
            padding: 0;
        }

        .pipeline {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .pipeline-step {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 10px;
            padding: 1.25rem;
            text-align: center;
            position: relative;
        }

        .pipeline-step::after {
            content: '→';
            position: absolute;
            right: -0.75rem;
            top: 50%;
            transform: translateY(-50%);
            color: var(--accent);
            font-size: 1.2rem;
        }

        .pipeline-step:last-child::after {
            display: none;
        }

        .step-num {
            background: var(--accent);
            color: var(--bg-primary);
            width: 28px;
            height: 28px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            font-size: 0.85rem;
            margin: 0 auto 0.75rem;
        }

        .step-title {
            font-weight: 600;
            font-size: 0.95rem;
        }

        a {
            color: var(--accent);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .cta {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            background: var(--accent);
            color: var(--bg-primary);
            padding: 0.75rem 1.5rem;
            border-radius: 8px;
            font-weight: 600;
            margin-top: 1rem;
            transition: opacity 0.2s;
        }

        .cta:hover {
            opacity: 0.9;
            text-decoration: none;
        }

        footer {
            text-align: center;
            padding: 3rem 0;
            margin-top: 3rem;
            border-top: 1px solid var(--border);
            color: var(--text-secondary);
        }

        @media (max-width: 600px) {
            .logo { font-size: 2.5rem; }
            .container { padding: 1rem; }
            .pipeline-step::after { display: none; }
        }
    </style>
</head>
<body>
    <div class="grain"></div>
    
    <div class="container">
        <header>
            <div class="logo">LocalLoRA</div>
            <p class="tagline">Fine-tune LLMs locally on Apple Silicon using MLX</p>
            <div class="badges">
                <span class="badge accent">M4 Max Optimized</span>
                <span class="badge">MLX Framework</span>
                <span class="badge">Ollama Compatible</span>
                <span class="badge">~30 min training</span>
            </div>
        </header>

        <section>
            <h2>Pipeline Overview</h2>
            <div class="pipeline">
                <div class="pipeline-step">
                    <div class="step-num">1</div>
                    <div class="step-title">Scrape Papers</div>
                </div>
                <div class="pipeline-step">
                    <div class="step-num">2</div>
                    <div class="step-title">Process PDFs</div>
                </div>
                <div class="pipeline-step">
                    <div class="step-num">3</div>
                    <div class="step-title">Train LoRA</div>
                </div>
                <div class="pipeline-step">
                    <div class="step-num">4</div>
                    <div class="step-title">Export to Ollama</div>
                </div>
            </div>
        </section>

        <section>
            <h2>Frequently Asked Questions</h2>

            <div class="faq-item">
                <div class="faq-question">How do I get started?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>Clone the repo and install dependencies with uv:</p>
<pre><code>git clone https://github.com/james-see/locallora.git
cd locallora
uv sync</code></pre>
                        <p>Then follow the pipeline: scrape → process → train → export.</p>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How do I scrape research papers?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>The scraper pulls from arXiv, NASA ADS, and Semantic Scholar:</p>
<pre><code># Preview what will be downloaded
uv run python scrape_gravity_papers.py --dry-run

# Download papers
uv run python scrape_gravity_papers.py --max-per-query 20</code></pre>
                        <p>Papers are saved to the <code>papers/</code> directory.</p>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How do I process PDFs into training data?</div>
                <div class="faq-answer">
                    <div class="faq-content">
<pre><code>uv run python processgravitydocs.py --pdf-folder papers</code></pre>
                        <p>This creates <code>papers_text.jsonl</code> with chunked text ready for training.</p>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How long does training take?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>On M4 Max with MLX: <strong>~30 minutes</strong> for 1000 iterations with 50 papers.</p>
                        <p>Estimate your training time:</p>
<pre><code>uv run python estimate_training.py</code></pre>
                        <p>MLX is 5-10x faster than PyTorch MPS for training on Apple Silicon.</p>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How do I train the LoRA adapter?</div>
                <div class="faq-answer">
                    <div class="faq-content">
<pre><code>uv run python train_mlx.py --batch-size 4 --iters 1000</code></pre>
                        <p>Key options:</p>
                        <ul>
                            <li><code>--batch-size</code>: 4-8 for 128GB RAM</li>
                            <li><code>--iters</code>: Training iterations</li>
                            <li><code>--learning-rate</code>: Default 1e-5</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">Can I continue training from an existing adapter?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>Yes! Use the <code>--resume</code> flag:</p>
<pre><code># Add more papers and reprocess
uv run python scrape_gravity_papers.py --max-per-query 50
uv run python processgravitydocs.py

# Continue training
uv run python train_mlx.py --resume auto --iters 500</code></pre>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How do I test the model before exporting?</div>
                <div class="faq-answer">
                    <div class="faq-content">
<pre><code># Interactive chat
uv run python chat_with_model.py

# Single prompt
uv run python -m mlx_lm generate \
    --model mistralai/Ministral-8B-Instruct-2410 \
    --adapter-path ./output/mlx-lora/adapter \
    --prompt "[INST] Explain gravitational waves [/INST]"</code></pre>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">How do I export to Ollama?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>Three steps: fuse, convert, create:</p>
<pre><code># 1. Fuse adapter into base model
uv run python -m mlx_lm fuse \
    --model mistralai/Ministral-8B-Instruct-2410 \
    --adapter-path ./output/mlx-lora/adapter \
    --save-path ./output/my-model

# 2. Convert to GGUF
python convert_hf_to_gguf.py ./output/my-model \
    --outfile ./output/my-model.gguf --outtype f16

# 3. Create Ollama model
cd output
echo 'FROM ./my-model.gguf' > Modelfile
ollama create my-model -f Modelfile

# 4. Run it!
ollama run my-model</code></pre>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">What if I run out of memory?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>Reduce batch size and number of LoRA layers:</p>
<pre><code>uv run python train_mlx.py --batch-size 1 --num-layers 8</code></pre>
                    </div>
                </div>
            </div>

            <div class="faq-item">
                <div class="faq-question">Can I use a different base model?</div>
                <div class="faq-answer">
                    <div class="faq-content">
                        <p>Yes! Edit <code>config.yml</code> and change <code>base_model</code>:</p>
<pre><code>base_model: mistralai/Mistral-7B-v0.3
# or
base_model: meta-llama/Llama-3.2-3B</code></pre>
                        <p>Any HuggingFace model compatible with MLX will work.</p>
                    </div>
                </div>
            </div>

        </section>

        <section style="text-align: center; margin-top: 3rem;">
            <a href="https://github.com/james-see/locallora" class="cta">
                View on GitHub →
            </a>
        </section>

        <footer>
            <p>Built for Apple Silicon • MIT License • 2026</p>
        </footer>
    </div>

    <script>
        document.querySelectorAll('.faq-question').forEach(q => {
            q.addEventListener('click', () => {
                q.parentElement.classList.toggle('open');
            });
        });
    </script>
</body>
</html>
